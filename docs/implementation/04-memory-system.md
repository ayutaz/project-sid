# 4. 記憶システム設計

[← 実装ドキュメント トップ](./index.md)

---

## 4.1 概要

PIANOアーキテクチャの記憶（Memory）モジュールは、エージェントの会話・行動・観察を保存・検索する中核コンポーネントである。ベースラインアーキテクチャにも含まれる基本モジュールであり、すべての上位認知モジュール（目標生成、社会認識、自己省察、計画）が記憶に依存する。

論文では**作業記憶（WM）・短期記憶（STM）・長期記憶（LTM）**の三層構造が示されているが、具体的な時間パラメータや容量制限は明記されていない。本ドキュメントでは、論文の記述、認知科学の知見、先行研究（Generative Agents、MemGPT）を踏まえ、再現実装のための設計を提案する。

### 設計原則

1. **ステートレスモジュール設計**: PIANOの原則に従い、記憶モジュールは共有エージェント状態に対して読み書きするステートレスな操作として機能する
2. **可変速度対応**: 高速な記憶検索（Action Awarenessへの応答）と低速な記憶統合（反省・圧縮）を並行処理
3. **500-1000エージェント規模のスケーラビリティ**: 文明シミュレーション（500体、2.5時間）で破綻しない設計
4. **認知コントローラとの統合**: CCが記憶からの情報をボトルネックとして圧縮し、ブロードキャストする

---

## 4.2 三層記憶構造の設計

### 4.2.1 作業記憶（Working Memory: WM）

**役割**: エージェントの「今この瞬間」の状態表現を保持する。CCの情報ボトルネックに直接供給される。

| パラメータ | 提案値 | 根拠 |
|---|---|---|
| データ構造 | 構造化JSON（キー・バリュー形式） | 高速アクセスが必要、検索不要 |
| 容量 | 最大1,200トークン相当（CCプロンプト配分の30%） | 下記トークン配分設計に基づく |
| 更新頻度 | 毎ティック（1-5秒） | Action Awarenessの高速サイクルに対応 |
| 永続化 | 不要（インメモリのみ） | セッション中のみ有効 |

**CCプロンプト全体のトークン配分設計**:

CCのプロンプトにはWM以外にも複数の情報源が注入される。LLMのコンテキストウィンドウを有効活用するため、CCプロンプト入力全体の上限を**4,096トークン**とし、以下のように配分する。

| セクション | 配分 | トークン数 | 内容 |
|---|---|---|---|
| システムプロンプト | 10% | ~400 | 役割定義、性格特性、行動原則 |
| **作業記憶（WM）** | **30%** | **~1,200** | 現在の状態、位置、インベントリ、周囲 |
| 目標・計画 | 15% | ~600 | active_goals、現在のプラン |
| 社会的状況 | 15% | ~600 | 近傍エージェント、関係性、会話履歴 |
| 関連記憶（STM/LTM検索結果） | 20% | ~800 | 検索で取得した上位記憶 |
| 行動認識・緊急情報 | 10% | ~400 | AAアラート、環境変化 |

この配分はCC情報ボトルネックの圧縮度に応じて動的に調整可能。緊急時は行動認識の配分を増やし、社会的インタラクション中は社会的状況の配分を増やす。

**WMのスキーマ設計**:

```json
{
  "agent_id": "agent_001",
  "timestamp": "2024-01-01T00:00:00Z",
  "location": {
    "x": 100, "y": 64, "z": -200,
    "biome": "forest",
    "nearby_structures": ["house_north", "farm_east"]
  },
  "inventory_summary": "木のツルハシ, パン x3, 石炭 x5",
  "health": 18,
  "hunger": 15,
  "current_action": {
    "type": "mining",
    "target": "iron_ore",
    "started_at": "2024-01-01T00:00:00Z",
    "expected_result": "iron_ore x1"
  },
  "nearby_agents": [
    {"id": "agent_042", "name": "Lila", "distance": 5, "activity": "farming"}
  ],
  "active_goals": ["鉄インゴットを精錬する", "Lilaと協力する"],
  "cc_broadcast": "農場エリアで採掘を継続。Lilaが近くで農作業中。",
  "emotional_state": {
    "valence": 0.7,
    "arousal": 0.3
  }
}
```

**更新ロジック**:
- 環境観察（知覚入力）から自動更新: 位置、インベントリ、周囲のエージェント
- Action Awarenessからのフィードバック: current_actionの期待結果と実際の結果の比較
- CCからのブロードキャスト受信: cc_broadcastフィールドの更新
- 目標生成モジュールからの出力: active_goalsの更新

### 4.2.2 短期記憶（Short-Term Memory: STM）

**役割**: 最近の会話や観察を時系列で保持する。Social AwarenessやGoal Generationが参照する。

| パラメータ | 提案値 | 根拠 |
|---|---|---|
| データ構造 | 時系列イベントリスト + ベクトルインデックス | 時間順アクセスと類似度検索の両立 |
| 容量 | 動的（下記参照） | シミュレーション時間に応じて調整 |
| 保持期間 | ゲーム内約30分（実時間準拠） | 短期実験の全期間をカバー |
| 永続化 | オプショナル（Redis等のインメモリDB） | 高速アクセス優先 |

**STM容量の動的調整**:

STMの容量はシミュレーション時間に応じて動的に調整する。イベント生成レート（約1件/10秒）を考慮すると、短期実験（30分）では約180件、長時間実験（4時間）では約1,440件のイベントが発生する。

| シミュレーション時間 | STM容量 | LTM統合間隔 | 根拠 |
|---|---|---|---|
| ~30分 | 100件 | 10分ごと | 実験全体をSTMでカバー可能 |
| 1-2時間 | 200件 | 5分ごと | 直近20-30分の履歴を保持 |
| 2-4時間 | 300件 | 3分ごと | LTM統合頻度を上げて負荷分散 |

```python
def calculate_stm_capacity(simulation_duration_hours: float) -> int:
    """シミュレーション時間に基づくSTM容量の計算"""
    base_capacity = 100
    # 1時間ごとに100件追加、上限300件
    return min(base_capacity + int(simulation_duration_hours) * 100, 300)
```

統合間隔もSTM容量に連動して短縮することで、容量超過による一括統合（LLMコストのスパイク）を防止する。

**STMイベントのスキーマ**:

```json
{
  "event_id": "evt_20240101_000100_001",
  "timestamp": "2024-01-01T00:01:00Z",
  "type": "conversation | action | observation | reflection",
  "content": "Lilaが「一緒に鉄を採掘しよう」と提案した",
  "participants": ["agent_001", "agent_042"],
  "location": {"x": 100, "y": 64, "z": -200},
  "importance": 0.7,
  "embedding": [0.12, -0.34, ...],
  "metadata": {
    "emotion_detected": "friendly",
    "topic": "collaboration"
  }
}
```

**重要度スコアリング**（importance: 0.0-1.0）:
- **会話イベント**: 基本スコア0.5。直接的な依頼/提案は+0.2、感情的な内容は+0.1
- **行動イベント**: 基本スコア0.3。目標関連の行動は+0.3、失敗した行動は+0.2
- **観察イベント**: 基本スコア0.2。新しいエージェントの発見は+0.3、危険の検知は+0.4
- **省察イベント**: 基本スコア0.6。高次の推論結果は常に高重要度

### 4.2.3 長期記憶（Long-Term Memory: LTM）

**役割**: 長期にわたる履歴を保持する。文明シミュレーション（2.5時間、500体）での文化的記憶と伝達の基盤。

| パラメータ | 提案値 | 根拠 |
|---|---|---|
| データ構造 | ベクトルDB + メタデータフィルタリング | 大規模検索に対応 |
| 容量 | エージェントあたり最大10,000件 | 2.5時間のシミュレーションで十分 |
| 保持期間 | シミュレーション全期間 | 永続的 |
| 永続化 | ベクトルDB（Qdrant推奨） | スケーラビリティと永続性 |

**LTMレコードのスキーマ**:

```json
{
  "memory_id": "mem_agent001_00042",
  "agent_id": "agent_001",
  "created_at": "2024-01-01T00:30:00Z",
  "last_accessed": "2024-01-01T01:15:00Z",
  "access_count": 3,
  "type": "episodic | semantic | procedural",
  "content": "Lilaは信頼できるパートナーで、採掘で2回協力した",
  "summary": "Lilaとの協力関係",
  "importance": 0.8,
  "embedding": [0.12, -0.34, ...],
  "tags": ["relationship", "Lila", "mining", "cooperation"],
  "source_events": ["evt_20240101_000100_001", "evt_20240101_001500_003"],
  "decay_factor": 1.0
}
```

**記憶の種類**:
- **エピソード記憶（episodic）**: 具体的な出来事の記録（「LilaとNoahが農場で口論した」）
- **セマンティック記憶（semantic）**: 抽象化された知識（「Lilaは農業が得意」）
- **手続き記憶（procedural）**: 行動パターンの記録（「鉄を精錬するには、かまどと石炭が必要」）

---

## 4.3 層間遷移ルール

### WM → STM 遷移

```
トリガー: WMで処理されたイベントが完了した時
条件: importance >= 0.2（ほぼすべてのイベントが遷移）
処理:
  1. WMのcurrent_action完了時にSTMイベントを生成
  2. 会話終了時にSTMイベントを生成
  3. エンベディングを計算してSTMインデックスに追加
```

### STM → LTM 遷移（統合プロセス）

```
トリガー: 以下のいずれか
  (a) STMが動的容量上限に達した時（最古のイベントから統合、容量はセクション4.2.2参照）
  (b) 定期的な統合サイクル（シミュレーション時間に応じて3-10分ごと）
  (c) 自己省察モジュールからの明示的トリガー

処理:
  1. 類似イベントのクラスタリング（コサイン類似度 >= 0.85）
  2. クラスタ内のイベントをLLMで要約（圧縮）
  3. エピソード記憶 → セマンティック記憶への昇華
     例: 「Lilaと3回採掘した」→「Lilaは信頼できる採掘パートナー」
  4. 重要度の再計算（アクセス頻度を加味）
  5. LTMベクトルDBに永続化
  6. 元のSTMイベントを削除

統合プロンプト例:
  "以下のイベント群を1つの要約記憶に統合してください。
   重要な人物関係、学んだこと、感情的な意味を保持してください。"
```

### LTM内の忘却・圧縮

```
忘却戦略:
  decay_factor = importance * recency_weight * access_weight

  recency_weight = exp(-lambda * time_since_creation_hours)
    lambda = 0.5（時間単位: 時間。半減期 ≈ 1.4時間）
    # 具体例: 1時間後 → exp(-0.5) ≈ 0.61、2.5時間後 → exp(-1.25) ≈ 0.29
    # セクション4.6.1の検索recency関数と同一パラメータ

  access_weight = log(1 + access_count) / log(1 + max_access_count)

圧縮トリガー:
  LTMが容量上限（10,000件）の80%に達した時
  decay_factor < 0.1 の記憶を候補としてLLM要約で統合

削除基準:
  decay_factor < 0.05 かつ access_count == 0 の記憶を削除
```

---

## 4.4 ベクトルデータベース選定

### 候補比較

| 項目 | Qdrant | Milvus | Weaviate | Chroma | Pinecone |
|---|---|---|---|---|---|
| **言語** | Rust | Go/C++ | Go | Python/Rust | マネージド |
| **ライセンス** | Apache 2.0 | Apache 2.0 | BSD-3 | Apache 2.0 | プロプライエタリ |
| **クエリ遅延** | 1-5ms (*1) | ~5ms | ~10ms | ~20ms | ~10ms |
| **スループット** | 数百-数千 QPS (*1) | 3,000+ QPS | 1,500 QPS | 300 QPS | 1,000+ QPS |
| **メモリ使用** | 5.5GB (100万ベクトル) | 高め | 高め | 3.5GB | N/A |
| **最大スケール** | 数十億 | 数兆 | ~5,000万 | ~1,000万 | 数十億 |
| **フィルタリング** | payload-aware HNSW | 高度 | GraphQL | 基本的 | メタデータ |
| **量子化** | バイナリ/非対称 | PQ/SQ | なし | なし | なし |
| **セルフホスト** | 容易 | 中程度 | 容易 | 非常に容易 | 不可 |
| **クラスタリング** | Raft対応 | 分散対応 | Raft対応 | 非対応 | マネージド |
| **GPU加速** | なし | あり | なし | なし | N/A |

> (*1) Qdrantの性能はデータ規模・recall設定・フィルタリング条件に大きく依存する。大規模ベンチマーク（50Mベクトル、99% recall）では41-50 QPS程度まで低下する報告もある。本設計ではagent_idパーティショニング（各パーティション最大10,000ベクトル）を前提としており、この規模では1-5msの遅延で十分な性能が期待できる。

### 500-1000エージェント規模の試算

```
エージェント数: 1,000
エージェントあたりLTMレコード: 最大 10,000
ベクトル次元: 1,536（text-embedding-3-large）
合計ベクトル数: 10,000,000（1,000万）

ストレージ試算:
  ベクトルサイズ: 1,536 * 4 bytes = 6,144 bytes/ベクトル
  メタデータ: 約 500 bytes/ベクトル
  合計: 約 6,644 bytes * 10,000,000 = 約 62 GB

クエリ要件:
  同時クエリ: 1,000エージェント * 0.2 QPS（平均） = 200 QPS
  ピーク: 1,000エージェント * 1.0 QPS = 1,000 QPS
  レイテンシ要件: p95 < 50ms
```

### 推奨: Qdrant（セルフホスト）

**選定理由**:

1. **パフォーマンス**: agent_idパーティショニング前提（各パーティション最大10,000ベクトル）で1-5msのクエリ遅延が期待できる。1,000エージェントのピーク要件（1,000 QPS）に対しては、パーティション単位の検索が小規模であるため十分に対応可能。なお、大規模データセット（50M+ベクトル）に対する単一クエリでは性能が大幅に低下するため、パーティショニング戦略が必須
2. **フィルタリング**: payload-aware HNSWにより、`agent_id`でのフィルタリングがベクトル検索と統合実行される。エージェントごとの記憶分離に最適
3. **量子化**: バイナリ量子化でメモリフットプリントを1/32に削減可能（62GB → 約2GB）。精度低下は検索リランキングで補償
4. **セルフホスト容易性**: Dockerイメージで即座にデプロイ可能。ローカル開発と本番環境で同一アーキテクチャ
5. **Raftクラスタリング**: 1,000万ベクトル超の場合はシャーディングで水平スケール可能
6. **コスト**: セルフホストのためランニングコストはインフラ費用のみ

**代替候補**:
- **開発・プロトタイプ段階**: Chroma（セットアップが最も簡単、Python統合が容易）
- **PostgreSQL統合**: pgvectorscale（PostgreSQL拡張）。ベンチマークではQdrantを上回るスループット（同条件で471-1,589 QPS）を示す報告がある。PIANOで既にPostgreSQLを使用する場合（Mineflayer状態管理等）、インフラの統合による運用簡素化が期待できる
- **超大規模展開（1万エージェント以上）**: Milvus（GPU加速、分散処理に優れる）
- **マネージド運用優先**: Pinecone Serverless（運用負荷ゼロ、ただし$50/月〜のコスト）

---

## 4.5 記憶のエンコーディング

### 4.5.1 テキストエンベディングモデル選定

| モデル | 次元 | MTEB | コスト(/1Mトークン) | コンテキスト長 | 備考 |
|---|---|---|---|---|---|
| OpenAI text-embedding-3-large | 3,072 (可変) | 64.6 | $0.13 | 8,191 | 次元削減可能 |
| OpenAI text-embedding-3-small | 1,536 | 62.3 | $0.02 | 8,191 | コスト効率良 |
| Cohere embed-v4 | 1,024 | 65.2 | $0.10 | 512 | MTEB最高 |
| Voyage voyage-3.5 | 1,024 | 高 | $0.06 | 32,000 | 長文対応 |
| Nomic Embed Text V2 | 768 | 高 | 無料(セルフホスト) | 8,192 | MoE、セルフホスト可 |

**推奨: OpenAI text-embedding-3-small（1,536次元）**

- コストと性能のバランスが最良（$0.02/1Mトークン）
- 500エージェント * 10,000記憶 * 平均50トークン = 2.5億トークン → **約$5**で全記憶をエンベディング
- Qdrantのバイナリ量子化と組み合わせてメモリ効率を最適化
- 必要に応じてtext-embedding-3-large（3,072次元→1,536次元に削減）にアップグレード可能

**代替（セルフホスト）**: Nomic Embed Text V2
- API依存を排除したい場合に有効
- GPUサーバー（A10G等）でセルフホスト運用
- レイテンシは高くなるがランニングコストが低い

### 4.5.2 コスト試算（2.5時間シミュレーション）

```
前提:
  エージェント数: 500
  イベント生成レート: 1件/10秒（会話+行動+観察）
  シミュレーション時間: 9,000秒
  イベントあたり平均トークン: 50

STMイベント総数: 500 * 900 = 450,000
LTM統合後記憶数: 450,000 / 5（圧縮率）= 90,000
エンベディング対象トークン: 450,000 * 50 = 22,500,000

エンベディングコスト（text-embedding-3-small）:
  22,500,000 / 1,000,000 * $0.02 = $0.45

LTM統合のLLM呼び出し:
  統合回数: 90,000 / 5（バッチ）= 18,000回
  入力: 250トークン/回、出力: 100トークン/回
  GPT-4o-mini使用: 18,000 * (250 * $0.15 + 100 * $0.60) / 1,000,000 = $1.76

記憶システム合計コスト: 約 $2.21 / シミュレーション
```

### 4.5.3 重要度スコアリングの実装

重要度スコアはSTM登録時に計算し、LTM統合時に再計算する。

**方式1: ルールベース（高速、コスト低）**

```python
def calculate_importance(event: MemoryEvent) -> float:
    base_scores = {
        "conversation": 0.5,
        "action": 0.3,
        "observation": 0.2,
        "reflection": 0.6,
    }
    score = base_scores[event.type]

    # 会話の修飾子
    if event.type == "conversation":
        if event.has_request or event.has_proposal:
            score += 0.2
        if event.emotion_intensity > 0.5:
            score += 0.1

    # 行動の修飾子
    if event.type == "action":
        if event.is_goal_related:
            score += 0.3
        if event.is_failure:
            score += 0.2

    # 観察の修飾子
    if event.type == "observation":
        if event.new_agent_discovered:
            score += 0.3
        if event.threat_detected:
            score += 0.4

    return min(score, 1.0)
```

**方式2: LLMベース（高精度、コスト高）** — Generative Agentsに準拠

```
プロンプト:
"以下の記憶の重要度を1-10で評価してください。
 1は日常的で忘れても問題ない出来事、
 10は人生を変えるような重大な出来事です。

 記憶: {content}
 重要度:"
```

**推奨**: 方式1をデフォルトとし、LTM統合時のみ方式2で重要度を再評価する。これにより高速性とコスト効率を維持しつつ、長期記憶の質を確保する。

---

## 4.6 検索・保存戦略

### 4.6.1 検索アルゴリズム

記憶検索は**ハイブリッドスコアリング**で実現する。Generative Agentsの三要素（recency, importance, relevance）を拡張する。

```
final_score = alpha * relevance + beta * recency + gamma * importance

デフォルトパラメータ:
  alpha = 0.5  (意味的関連性)
  beta  = 0.3  (時間的近接性)
  gamma = 0.2  (重要度)
```

**relevance（意味的関連性）**: クエリベクトルと記憶ベクトルのコサイン類似度

```
relevance = cosine_similarity(query_embedding, memory_embedding)
```

**recency（時間的近接性）**: 指数減衰関数

```
recency = exp(-lambda * hours_since_creation)
lambda = 0.5  # 半減期 ≈ 1.4時間
```

**importance（重要度）**: 4.5.3節で計算されたスコア

### 4.6.2 検索フロー

```
1. クエリの生成
   - CCまたは各モジュールが検索クエリをテキストで生成
   - 例: "Lilaとの最近の協力関係について"

2. WM検索（即時、< 1ms）
   - WMの構造化データから直接参照
   - nearby_agents, active_goals等

3. STM検索（高速、< 5ms）
   - 時系列フィルタ + ベクトル類似度
   - 最近100件から上位k件（k=5-10）を返す

4. LTM検索（中速、< 50ms）
   - Qdrantのベクトル検索 + メタデータフィルタ
   - agent_idでフィルタ後、ハイブリッドスコアで上位k件（k=5-10）

5. マージ・ランキング
   - STM/LTMの検索結果をfinal_scoreで統合ランキング
   - 上位k件（k=5-15、モジュールの要求に応じて可変）を返す
   - 重複除去（source_eventsの重複チェック）
```

### 4.6.3 モジュール別の検索パターン

| モジュール | 検索対象 | alpha/beta/gamma | 上位k |
|---|---|---|---|
| Action Awareness | WMのみ | N/A（直接参照） | N/A |
| Social Awareness | STM + LTM | 0.4 / 0.4 / 0.2 | 10 |
| Goal Generation | LTM（セマンティック） | 0.6 / 0.1 / 0.3 | 10 |
| Planning | STM + LTM | 0.5 / 0.3 / 0.2 | 15 |
| Self-Reflection | LTM（エピソード） | 0.3 / 0.2 / 0.5 | 20 |
| Talking | STM（会話） | 0.3 / 0.5 / 0.2 | 5 |
| CC | WM + STM（上位） | 0.4 / 0.4 / 0.2 | 10 |

### 4.6.4 記憶の圧縮・要約（LLMによる統合）

STMからLTMへの遷移時、および定期的なLTM内メンテナンスで記憶を圧縮する。

**統合プロンプト**:

```
あなたはエージェント{agent_name}の記憶管理システムです。

以下の関連する記憶群を、1つの簡潔な要約記憶に統合してください。

## 統合対象の記憶:
{memory_list}

## 要件:
- 重要な人物関係を保持すること
- 学んだ教訓や知識を保持すること
- 感情的に重要な要素を保持すること
- 具体的な詳細より抽象的なパターンを優先すること
- 1-3文で要約すること

## 出力形式:
{
  "summary": "要約テキスト",
  "type": "episodic | semantic | procedural",
  "tags": ["タグ1", "タグ2"],
  "importance": 0.0-1.0
}
```

---

## 4.7 先行研究との比較

### 4.7.1 Stanford Generative Agents との比較

| 観点 | Generative Agents | PIANO記憶システム（本提案） |
|---|---|---|
| **記憶構造** | 単一のメモリストリーム | WM/STM/LTMの三層構造 |
| **検索要素** | recency, importance, relevance | 同三要素 + モジュール別重み調整 |
| **反省（Reflection）** | 重要度蓄積がしきい値超過で発動 | 自己省察モジュールが独立して並行実行 |
| **計画** | 日単位の計画を生成 | 計画モジュールが並行して動的更新 |
| **スケール** | 25体 | 500-1000体を想定 |
| **一貫性制御** | なし（各エージェントが独立） | CCによるボトルネック+ブロードキャスト |
| **実行モデル** | 逐次実行 | 並列実行（ステートレスモジュール） |
| **ストレージ** | インメモリ（JSON） | ベクトルDB（Qdrant） |

**Generative Agentsからの採用要素**:
- 三要素（recency, importance, relevance）によるハイブリッド検索
- 重要度のLLM評価（LTM統合時）
- 反省による高次記憶の生成

**Generative Agentsからの改善点**:
- 単一メモリストリームを三層に分離し、アクセスパターンに最適化
- ベクトルDBによる大規模スケーラビリティ
- モジュール別の検索パラメータ調整
- CCによる記憶情報の統合・圧縮

### 4.7.2 MemGPT との比較

| 観点 | MemGPT | PIANO記憶システム（本提案） |
|---|---|---|
| **設計思想** | OS的メモリ管理（仮想メモリ） | 認知科学的三層記憶 |
| **メモリ階層** | Core / Recall / Archival | WM / STM / LTM |
| **制御** | LLM自身がツール呼び出しで管理 | 記憶モジュールが自動管理 |
| **コンテキスト管理** | ページングによる仮想コンテキスト | CC情報ボトルネックによる圧縮 |
| **自己編集** | LLMがCore Memoryを直接編集 | 構造化されたWM更新ルール |
| **マルチエージェント** | 単一エージェント向け | 500-1000エージェント対応 |
| **コスト** | ツール呼び出しによるLLMコスト増 | ルールベース優先でコスト抑制 |

**MemGPTからの採用要素**:
- 階層的メモリのページング概念（STM ↔ LTM間のデータ移動）
- 重要な情報のCore Memory（WM相当）への昇格

**MemGPTからの改善点**:
- ツール呼び出しベースの自己管理ではなく、構造化ルールによる自動管理（LLMコスト削減）
- マルチエージェント環境での名前空間分離とスケーラビリティ

### 4.7.3 最新研究動向との比較

| 手法 | 概要 | 本提案への示唆 |
|---|---|---|
| **A-MEM (2025)** | Zettelkasten的ノート構造、動的リンク | LTM内でタグベースの関連付けを採用 |
| **AriGraph (2025)** | エピソード記憶をナレッジグラフに拡張 | 将来的にLTMのグラフDB拡張を検討 |
| **MIRIX (2025)** | マルチエージェント共有記憶 | 共有記憶層の追加を検討（文化伝播用） |
| **M2PA (2025)** | マルチメモリ計画エージェント | 計画モジュールとの記憶統合に参考 |

---

## 4.8 実装アーキテクチャ

### 4.8.1 コンポーネント構成

```
┌─────────────────────────────────────────────────┐
│                  Memory Module                   │
│                                                  │
│  ┌──────────┐  ┌──────────┐  ┌───────────────┐  │
│  │    WM    │  │   STM    │  │     LTM       │  │
│  │ (in-mem) │  │ (Redis)  │  │  (Qdrant)     │  │
│  │  JSON    │  │ + Vector │  │  Vector +     │  │
│  │  Store   │  │  Index   │  │  Metadata     │  │
│  └────┬─────┘  └────┬─────┘  └──────┬────────┘  │
│       │              │               │           │
│  ┌────┴──────────────┴───────────────┴────────┐  │
│  │          Memory Manager                     │  │
│  │  - 検索ルーティング                          │  │
│  │  - 層間遷移管理                              │  │
│  │  - 圧縮・忘却スケジューラ                     │  │
│  │  - エンベディング計算                         │  │
│  └────────────────────────────────────────────┘  │
│                      │                           │
│              ┌───────┴───────┐                    │
│              │  Memory API   │                    │
│              │  - store()    │                    │
│              │  - retrieve() │                    │
│              │  - update_wm()│                    │
│              │  - consolidate│                    │
│              └───────────────┘                    │
└─────────────────────────────────────────────────┘
         │                          │
    [共有エージェント状態]     [他のモジュール]
```

### 4.8.2 技術スタック

| コンポーネント | 技術選定 | 理由 |
|---|---|---|
| WM Store | Python dict / dataclass | 最速アクセス、構造化データ |
| STM Store | Redis + RedisSearch | インメモリ高速、TTL対応、ベクトル検索 |
| LTM Store | Qdrant (Docker) | スケーラブル、フィルタリング、永続化 |
| エンベディング | OpenAI text-embedding-3-small | コスト効率、十分な精度 |
| 圧縮LLM | GPT-4o-mini | 記憶統合に十分、低コスト |
| Memory Manager | Python (asyncio) | 非同期I/O、他モジュールとの統合 |

### 4.8.3 APIインターフェース

```python
class MemoryModule:
    """PIANOの記憶モジュール。ステートレスな操作として機能し、
    共有エージェント状態に対して読み書きを行う。"""

    async def store(
        self,
        agent_id: str,
        event: MemoryEvent,
    ) -> str:
        """イベントをSTMに保存する。
        重要度を計算し、エンベディングを生成してSTMに追加。
        STMが容量上限に達した場合はLTM統合をトリガー。
        Returns: event_id
        """
        ...

    async def retrieve(
        self,
        agent_id: str,
        query: str,
        module: str = "default",
        top_k: int = 10,
        layers: list[str] = ["stm", "ltm"],
    ) -> list[MemoryRecord]:
        """記憶を検索する。
        モジュール名に応じた重みパラメータを自動適用。
        WM/STM/LTMを指定された層から検索し、マージ結果を返す。
        """
        ...

    async def update_wm(
        self,
        agent_id: str,
        updates: dict,
    ) -> None:
        """作業記憶を部分更新する。
        環境観察、CCブロードキャスト、目標更新等。
        """
        ...

    async def get_wm(
        self,
        agent_id: str,
    ) -> WorkingMemory:
        """作業記憶の全体を取得する。
        CCの情報ボトルネック処理で使用。
        """
        ...

    async def consolidate(
        self,
        agent_id: str,
        force: bool = False,
    ) -> int:
        """STM→LTM統合を実行する。
        LLMによる要約・圧縮を含む。
        Returns: 統合された記憶の件数
        """
        ...

    async def maintenance(
        self,
        agent_id: str,
    ) -> None:
        """LTM内の忘却・圧縮メンテナンスを実行する。
        定期的にスケジューラから呼び出される。
        """
        ...

    # --- 共有記憶層（将来拡張用プレースホルダー） ---
    # 500体文明シミュレーションでは文化的記憶（法律、宗教、慣習等のミーム）の
    # エージェント間伝達が重要になる。Phase 0 MVPでは未実装だが、
    # インターフェースを予約しておくことで将来の拡張を容易にする。

    async def store_shared(
        self,
        memory: MemoryEvent,
        scope: str = "global",
        visible_to: list[str] | None = None,
    ) -> str:
        """共有記憶を保存する（将来拡張用）。
        scope: "global"（全エージェント共有）, "group"（グループ内共有）, "bilateral"（二者間共有）
        visible_to: scope="group"/"bilateral"時のアクセス許可エージェントIDリスト
        Returns: shared_memory_id
        """
        raise NotImplementedError("共有記憶層はPhase 1以降で実装予定")

    async def retrieve_shared(
        self,
        agent_id: str,
        query: str,
        scope: str = "global",
        top_k: int = 5,
    ) -> list[MemoryRecord]:
        """共有記憶を検索する（将来拡張用）。
        エージェントがアクセス可能な共有記憶から、関連するものを検索する。
        """
        raise NotImplementedError("共有記憶層はPhase 1以降で実装予定")
```

---

## 4.9 スケーラビリティ設計

### 500-1000エージェント対応

| 課題 | 対策 |
|---|---|
| エンベディング計算の並列化 | バッチ処理（最大2048件/バッチ）でOpenAI APIに送信 |
| Qdrantクエリの同時実行 | agent_idによるコレクションシャーディング |
| Redis メモリ使用量 | エージェントごとにTTL付きキーを使用、100件/エージェント上限 |
| LLM統合の並列実行 | 統合タスクをキュー化し、ワーカープールで並列処理 |
| コスト管理 | ルールベース重要度を優先、LLM呼び出しは統合時のみ |

### デプロイ構成（500エージェント）

```
┌─────────────────────────────────────────┐
│  Memory Manager Workers (4-8 instances) │
│  - 各ワーカーが125-250エージェントを担当  │
│  - asyncioベースの非同期処理               │
└──────────┬──────────────────┬────────────┘
           │                  │
    ┌──────┴──────┐    ┌─────┴──────┐
    │   Redis     │    │   Qdrant   │
    │  Cluster    │    │  Cluster   │
    │  (STM)      │    │  (LTM)     │
    │  16GB RAM   │    │  32GB RAM  │
    │  3 nodes    │    │  3 nodes   │
    └─────────────┘    └────────────┘
```

**推定リソース要件（500エージェント、2.5時間）**:

| リソース | 要件 |
|---|---|
| Redis メモリ | ~2GB（500エージェント * 100件 * 4KB） |
| Qdrant ストレージ | ~6GB（500K記憶 * 12KB、量子化なし） |
| Qdrant メモリ | ~8GB（HNSWインデックス含む） |
| エンベディングAPI | ~$0.45（22.5Mトークン） |
| LLM統合API | ~$1.76（18K回の統合） |
| ネットワーク帯域 | ~100Mbps（ピーク時） |

---

## 4.10 制限事項と将来拡張

### 制限事項

1. **論文の不明点**: WM/STM/LTMの具体的な時間パラメータは論文に明記されておらず、本設計の値は認知科学の知見と実験規模から推定したもの
2. **記憶の信頼性**: LLMによる記憶統合は情報の損失や歪みを伴う可能性がある
3. **文化的記憶**: 500体規模の文化伝播実験では、エージェント間で記憶が伝達されるメカニズム（会話を通じた間接的伝達）の詳細設計が必要
4. **セマンティック検索の限界**: ベクトル類似度だけでは文脈的関連性を完全には捉えられない

### 将来拡張

1. **共有記憶層**: エージェント間で共有されるセマンティック記憶（文化、法律、宗教等のミーム）
2. **グラフベース記憶**: LTMの一部をナレッジグラフ（Neo4j等）で管理し、関係性推論を強化
3. **適応的パラメータ**: 検索重みやrecency減衰率をシミュレーション状況に応じて動的調整
4. **記憶の共有・伝達プロトコル**: 会話モジュールと連携し、記憶が他エージェントに伝播する明示的メカニズム
5. **マルチモーダル記憶**: Minecraft環境のビジュアル情報を記憶に統合

---

## 4.11 参考文献

- Park, J. S., et al. (2023). "Generative Agents: Interactive Simulacra of Human Behavior." UIST 2023.
- Packer, C., et al. (2023). "MemGPT: Towards LLMs as Operating Systems." arXiv:2310.08560.
- Altera.AL (2024). "Project Sid: Many-agent simulations toward AI civilization." arXiv:2411.00114.
- Xu, Z., et al. (2025). "A-MEM: Agentic Memory for LLM Agents." arXiv:2502.12110.
- Wang, Y. & Chen, X. (2025). "MIRIX: Multi-Agent Memory System for LLM-Based Agents." arXiv:2507.07957.

---

[← 実装ドキュメント トップ](./index.md)
