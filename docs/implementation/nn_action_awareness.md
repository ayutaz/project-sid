# Action Awareness Neural Network Implementation

> Implementation Status: **Complete** (Phase 1)
> Date: 2026-02-23
> Files Created: 3 (implementation + tests + demo)

---

## Overview

This document describes the neural network-based action awareness implementation for the PIANO architecture. The NN replaces/augments the Phase 0 rule-based action awareness with learned discrepancy detection.

## Implementation Summary

### Files Created

1. **`src/piano/awareness/nn_model.py`** (493 lines)
   - `NNConfig`: Pydantic configuration for network architecture
   - `FeedForwardNN`: Numpy-based feedforward network with ReLU/softmax
   - `ActionEncoder`: Encodes state + action into fixed-size vectors
   - `ActionOutcomePredictor`: Predicts outcomes and calculates discrepancies
   - `NNActionAwarenessModule`: Module integration with SAS

2. **`tests/unit/awareness/test_nn_model.py`** (577 lines)
   - 34 comprehensive tests covering all components
   - Tests for initialization, forward pass, encoding, prediction, discrepancy calculation
   - Integration tests with SAS
   - Save/load round-trip tests

3. **`examples/action_awareness_nn_demo.py`** (159 lines)
   - Interactive demonstration of all NN capabilities
   - Shows encoding, prediction, discrepancy calculation, and persistence

### Test Coverage

- **Total tests**: 34 (all passing)
- **Test categories**:
  - Configuration: 2 tests
  - FeedForwardNN: 8 tests
  - ActionEncoder: 7 tests
  - ActionOutcomePredictor: 6 tests
  - NNActionAwarenessModule: 8 tests
  - Integration: 3 tests

## Architecture Details

### Network Architecture

**Default configuration** (~19K parameters):
```
Input: 64 dimensions
Hidden: [128, 64, 32]
Output: 16 dimensions
Total parameters: 19,184
```

**~100K parameter configuration**:
```
Input: 128 dimensions
Hidden: [256, 192, 128]
Output: 32 dimensions
Total parameters: 111,200
```

### Network Characteristics

- **Activation**: ReLU (hidden layers), Softmax (output layer)
- **Initialization**: He initialization (optimal for ReLU)
- **Inference speed**: < 10ms on CPU (untrained network)
- **Framework**: Pure NumPy (no PyTorch/TensorFlow dependency)

### Encoding Strategy

The `ActionEncoder` converts state + action into a fixed-size vector using:

1. **Action type one-hot** (dims 0-7): move, mine, craft, chat, look, idle, attack, use
2. **Position** (dims 8-10): x, y, z coordinates (normalized)
3. **Health/Hunger** (dims 11-12): normalized 0-20
4. **Inventory size** (dim 13): total item count
5. **Time of day** (dim 14): normalized 0-24000
6. **Entity counts** (dims 15-17): nearby players, blocks, chat messages
7. **Goal hash** (dims 18-25): hashed goal string (8 bins)
8. **Weather** (dims 26-29): clear, rain, thunder, snow
9. **Context noise** (dims 30+): deterministic noise for diversity

### Output Interpretation

The network outputs a 16-dimensional vector:
- `output[0]`: Success probability (0-1)
- `output[1]`: Expected duration (normalized, multiply by 60 for seconds)
- `output[2]`: Risk score (0-1)
- `output[3-15]`: Additional features (reserved for future use)

### Discrepancy Calculation

The `calculate_discrepancy()` method compares predicted vs actual outcomes:

```python
discrepancy = 0.0

# Success discrepancy
if actual["success"] != predicted["success_probability"]:
    discrepancy += abs(actual_success - predicted_success)

# Duration discrepancy (normalized)
duration_diff = abs(actual_duration - predicted_duration) / 60.0
discrepancy += min(duration_diff, 1.0)

# Risk discrepancy (if error occurred)
if actual["error"]:
    discrepancy += abs(1.0 - predicted_risk)

return average_discrepancy  # 0 = identical, 1 = very different
```

**Threshold**: discrepancy > 0.5 triggers alert/replanning

## Module Integration

### SAS Integration

The `NNActionAwarenessModule` integrates with the PIANO architecture:

```python
async def tick(self, sas: SharedAgentState) -> ModuleResult:
    1. Read latest action and percepts from SAS
    2. Encode state and predict expected outcome
    3. Compare with actual outcome
    4. Calculate discrepancy score
    5. Return ModuleResult for CC compression
```

**Module properties**:
- Name: `action_awareness_nn`
- Tier: `FAST` (non-LLM, < 100ms)

### Output to Cognitive Controller

The module returns a `ModuleResult` with:
```python
{
    "discrepancies": [...],  # List of detected discrepancies
    "last_action_success": bool,
    "discrepancy_score": float,  # 0-1
    "predicted_success_prob": float,
    "predicted_duration": float,
    "predicted_risk": float,
}
```

## Persistence

### Save/Load

Models can be saved and loaded:

```python
# Save
nn.save("/path/to/model")
# Creates:
#   - weight_0.npy, weight_1.npy, ...
#   - bias_0.npy, bias_1.npy, ...
#   - config.json

# Load
nn.load("/path/to/model")
```

**Format**: NumPy `.npy` files (efficient, portable)

## Performance Characteristics

| Metric | Value |
|--------|-------|
| Forward pass (single sample) | < 1ms |
| Forward pass (batch of 10) | < 5ms |
| Encoding | < 1ms |
| Total inference time | < 10ms |
| Parameter count (default) | 19,184 |
| Parameter count (~100K) | 111,200 |
| Memory footprint | ~400KB (default), ~2MB (100K) |

## Future Work (Phase 2+)

### Training Pipeline

The network is currently initialized with random weights. To train it:

1. **Data collection**: Record (state, action, expected, actual) tuples during agent execution
2. **Labeling**: Automatic labeling from rule-based discrepancy detection
3. **Training**: Supervised learning to predict outcomes
4. **Validation**: F1 > 0.85 on held-out test set

See `src/piano/awareness/trainer.py` for training implementation (if available).

### Online Learning

For continuous improvement:
- Collect discrepancies during runtime
- Periodic fine-tuning (every 1000 actions)
- A/B testing between rule-based and NN-based detection

### Extended Features

- **Multi-task learning**: Predict multiple outcome aspects simultaneously
- **Temporal modeling**: Use LSTM/GRU for action sequences
- **Attention mechanism**: Focus on relevant state features
- **Ensemble**: Combine rule-based + NN predictions

## References

- **Design document**: `docs/implementation/07-goal-planning.md` (Section 3)
- **Rule-based implementation**: `src/piano/awareness/action.py`
- **Test suite**: `tests/unit/awareness/test_nn_model.py`
- **Demonstration**: `examples/action_awareness_nn_demo.py`

## Key Design Decisions

### Why NumPy instead of PyTorch?

1. **No heavy dependencies**: Avoids 500MB+ PyTorch installation
2. **Fast CPU inference**: < 10ms without GPU overhead
3. **Simple deployment**: No CUDA/cuDNN requirements
4. **Educational clarity**: Explicit implementation of forward pass

### Why feedforward instead of RNN/LSTM?

1. **Phase 1 scope**: Simple baseline for initial implementation
2. **Fast inference**: No sequential computation overhead
3. **Sufficient for**: Stateless outcome prediction (state is fully observable)
4. **Future extension**: Can be replaced with RNN/Transformer in Phase 2

### Why ~100K parameters?

1. **Balance**: Large enough for complex patterns, small enough for fast inference
2. **Practical**: ~2MB memory footprint
3. **Training**: Can be trained on 5K-10K examples
4. **Overfitting risk**: Moderate size reduces overfitting on limited data

---

**Implementation Status**: âœ… Complete (Phase 1)
- [x] Network architecture
- [x] Action encoding
- [x] Outcome prediction
- [x] Discrepancy calculation
- [x] SAS integration
- [x] Persistence (save/load)
- [x] Comprehensive tests (34 tests)
- [x] Demonstration script
- [x] Ruff lint clean
